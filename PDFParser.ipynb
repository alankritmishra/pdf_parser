{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries and define a custom warning filter\n",
                "import warnings\n",
                "\n",
                "# Define a custom filter function\n",
                "def custom_warning_filter(message, category, filename, lineno, file=None, line=None):\n",
                "    if \"camelot only works on text-based pages\" in str(message):\n",
                "        return\n",
                "    return warnings.defaultaction\n",
                "\n",
                "# Apply the custom filter\n",
                "warnings.showwarning = custom_warning_filter\n",
                "\n",
                "# Example code that generates the specific warning\n",
                "warnings.warn(\"camelot only works on text-based pages\", UserWarning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries for PDF processing and extraction\n",
                "import os\n",
                "import logging\n",
                "import time\n",
                "import json\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "from typing import Dict, List, Optional, Tuple, Union\n",
                "from dataclasses import dataclass, asdict\n",
                "from enum import Enum\n",
                "\n",
                "# Add these imports at the top\n",
                "import pdfplumber\n",
                "import pytesseract\n",
                "from pytesseract import Output\n",
                "\n",
                "# Core PDF processing libraries\n",
                "import pymupdf\n",
                "import camelot\n",
                "import pandas as pd\n",
                "from PIL import Image\n",
                "import io\n",
                "# from unstructured.partition.pdf import partition_pdf\n",
                "from langchain.document_loaders import PyPDFLoader\n",
                "\n",
                "# Define enums and data classes for extraction methods and statistics\n",
                "class ExtractionMethod(Enum):\n",
                "    \"\"\"Available extraction methods\"\"\"\n",
                "    PYMUPDF = \"pymupdf\"\n",
                "    # UNSTRUCTURED = \"unstructured\"\n",
                "    CAMELOT = \"camelot\"\n",
                "    PYPDF = \"pypdf\"\n",
                "    PDFPLUMBER = \"pdfplumber\"\n",
                "\n",
                "\n",
                "@dataclass\n",
                "class ExtractionStats:\n",
                "    \"\"\"Statistics for extraction process\"\"\"\n",
                "    method: str\n",
                "    start_time: datetime\n",
                "    end_time: datetime\n",
                "    execution_time: float\n",
                "    memory_usage_mb: float\n",
                "    num_pages: int\n",
                "    items_extracted: int\n",
                "    success: bool\n",
                "    error_message: Optional[str] = None\n",
                "    additional_info: Optional[Dict] = None\n",
                "\n",
                "# Define the main PDFExtractor class\n",
                "class PDFExtractor:\n",
                "    \"\"\"\n",
                "    PDF Extractor with multiple extraction methods\n",
                "    \n",
                "    Features:\n",
                "    - Multiple text extraction methods (PyMuPDF, Unstructured, PyPDF)\n",
                "    - Table extraction (Camelot, Unstructured)\n",
                "    - Image extraction (PyMuPDF)\n",
                "    - Comprehensive statistics and metadata\n",
                "    - Experiment logging\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(\n",
                "        self,\n",
                "        output_dir: str = \"extracted_content\",\n",
                "        extract_text_method: str = \"pymupdf\",\n",
                "        extract_tables_method: str = \"camelot\",\n",
                "        extract_images_method: str = \"pymupdf\",\n",
                "        save_metadata: bool = True,\n",
                "        log_level: str = \"INFO\",\n",
                "        experiment_name: Optional[str] = None\n",
                "    ):\n",
                "        # Setup logging\n",
                "        self.setup_logging(log_level)\n",
                "        \n",
                "        # Initialize parameters\n",
                "        self.output_dir = Path(output_dir)\n",
                "        self.save_metadata = save_metadata\n",
                "        self.experiment_name = experiment_name or datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                "        \n",
                "        # Validate and set extraction methods\n",
                "        self.methods = {\n",
                "            'text': self._validate_method(\n",
                "                extract_text_method, \n",
                "                ['pymupdf', 'pypdf']\n",
                "            ),\n",
                "            'tables': self._validate_method(\n",
                "                extract_tables_method, \n",
                "                ['camelot', 'pdfplumber']\n",
                "            ),\n",
                "            'images': self._validate_method(\n",
                "                extract_images_method, \n",
                "                ['pymupdf']\n",
                "            )\n",
                "        }\n",
                "        \n",
                "        # Setup directory structure\n",
                "        self.setup_directories()\n",
                "        \n",
                "        # Initialize statistics\n",
                "        self.current_stats = {}\n",
                "\n",
                "    def setup_logging(self, log_level: str):\n",
                "        \"\"\"Configure logging\"\"\"\n",
                "        self.logger = logging.getLogger(self.__class__.__name__)\n",
                "        self.logger.setLevel(log_level)\n",
                "        \n",
                "        if not self.logger.handlers:\n",
                "            handler = logging.StreamHandler()\n",
                "            formatter = logging.Formatter(\n",
                "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
                "            )\n",
                "            handler.setFormatter(formatter)\n",
                "            self.logger.addHandler(handler)\n",
                "\n",
                "    def setup_directories(self):\n",
                "        \"\"\"Create output directories\"\"\"\n",
                "        self.dirs = {\n",
                "            'text': self.output_dir / 'text',\n",
                "            'tables': self.output_dir / 'tables',\n",
                "            'images': self.output_dir / 'images',\n",
                "            'metadata': self.output_dir / 'metadata',\n",
                "            'experiments': self.output_dir / 'experiments'\n",
                "        }\n",
                "        \n",
                "        for path in self.dirs.values():\n",
                "            path.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    def _validate_method(self, method: str, valid_methods: List[str]) -> str:\n",
                "        \"\"\"Validate extraction method\"\"\"\n",
                "        method = method.lower()\n",
                "        if method not in valid_methods:\n",
                "            raise ValueError(\n",
                "                f\"Invalid method '{method}'. Valid options are: {valid_methods}\"\n",
                "            )\n",
                "        return method\n",
                "\n",
                "    def _get_memory_usage(self) -> float:\n",
                "        \"\"\"Get current memory usage in MB\"\"\"\n",
                "        import psutil\n",
                "        process = psutil.Process(os.getpid())\n",
                "        memory_usage = process.memory_info().rss / 1024 / 1024\n",
                "        return max(memory_usage, 0)\n",
                "    \n",
                "    # Add this new function to save metadata\n",
                "    def save_structured_metadata(self, extraction_type: str, page_num: int, item_num: int, metadata: Dict):\n",
                "        \"\"\"Save structured metadata for each extracted element\"\"\"\n",
                "        metadata_file = self.dirs['metadata'] / f'{extraction_type}_metadata.json'\n",
                "        \n",
                "        # Load existing metadata if file exists\n",
                "        if metadata_file.exists():\n",
                "            with open(metadata_file, 'r') as f:\n",
                "                all_metadata = json.load(f)\n",
                "        else:\n",
                "            all_metadata = {}\n",
                "        \n",
                "        # Create unique identifier for the item\n",
                "        item_id = f\"page_{page_num}_item_{item_num}\"\n",
                "        all_metadata[item_id] = {\n",
                "            'extraction_type': extraction_type,\n",
                "            'page_number': page_num,\n",
                "            'item_number': item_num,\n",
                "            'timestamp': datetime.now().isoformat(),\n",
                "            **metadata\n",
                "        }\n",
                "        \n",
                "        # Save updated metadata\n",
                "        with open(metadata_file, 'w') as f:\n",
                "            json.dump(all_metadata, f, indent=2)\n",
                "\n",
                "    def extract_text(self, pdf_path: str) -> Tuple[List[Dict], ExtractionStats]:\n",
                "        \"\"\"\n",
                "        Extract text using configured method\n",
                "        \n",
                "        Returns:\n",
                "            Tuple containing:\n",
                "            - List of dictionaries with extracted text and metadata\n",
                "            - ExtractionStats with performance metrics\n",
                "        \"\"\"\n",
                "        method = self.methods['text']\n",
                "        start_time = datetime.now()\n",
                "        start_mem = self._get_memory_usage()\n",
                "        \n",
                "        try:\n",
                "            docs = []\n",
                "            additional_info = {}\n",
                "            \n",
                "            if method == 'pymupdf':\n",
                "                doc = pymupdf.open(pdf_path)\n",
                "                num_pages = doc.page_count\n",
                "                \n",
                "                for page_num in range(num_pages):\n",
                "                    page = doc[page_num]\n",
                "                    text_dict = page.get_text(\"dict\")\n",
                "                    text = page.get_text()\n",
                "                    \n",
                "                    # Save text\n",
                "                    output_path = self.dirs['text'] / f'page_{page_num + 1}.txt'\n",
                "                    with open(output_path, 'w', encoding='utf-8') as f:\n",
                "                        f.write(text)\n",
                "                    \n",
                "                    # Save page metadata\n",
                "                    docs.append({\n",
                "                        'content': text,\n",
                "                        'metadata': {\n",
                "                            'page': page_num + 1,\n",
                "                            'method': method,\n",
                "                            'blocks': text_dict.get('blocks', []),\n",
                "                            'file_path': str(output_path)\n",
                "                        }\n",
                "                    })\n",
                "                    \n",
                "                    # Collect additional information\n",
                "                    additional_info[f'page_{page_num + 1}'] = {\n",
                "                        'word_count': len(text.split()),\n",
                "                        'char_count': len(text)\n",
                "                    }\n",
                "                \n",
                "            elif method == 'pypdf':\n",
                "                loader = PyPDFLoader(pdf_path)\n",
                "                langchain_docs = loader.load()\n",
                "                num_pages = len(langchain_docs)\n",
                "                \n",
                "                for page_num, doc in enumerate(langchain_docs):\n",
                "                    output_path = self.dirs['text'] / f'page_{page_num + 1}.txt'\n",
                "                    with open(output_path, 'w', encoding='utf-8') as f:\n",
                "                        f.write(doc.page_content)\n",
                "                    \n",
                "                    docs.append({\n",
                "                        'content': doc.page_content,\n",
                "                        'metadata': {\n",
                "                            'page': page_num + 1,\n",
                "                            'method': method,\n",
                "                            'source': doc.metadata.get('source'),\n",
                "                            'file_path': str(output_path),\n",
                "                            'langchain_metadata': doc.metadata\n",
                "                        }\n",
                "                    })\n",
                "                    \n",
                "                    additional_info[f'page_{page_num + 1}'] = {\n",
                "                        'word_count': len(doc.page_content.split()),\n",
                "                        'char_count': len(doc.page_content)\n",
                "                    }\n",
                "                \n",
                "            # elif method == 'unstructured':\n",
                "            #     elements = partition_pdf(pdf_path, strategy=\"hi_res\")\n",
                "            #     page_texts = {}\n",
                "                \n",
                "            #     for elem in elements:\n",
                "            #         if hasattr(elem, 'metadata'):\n",
                "            #             page_num = elem.metadata.get('page_number', 0)\n",
                "            #             if page_num not in page_texts:\n",
                "            #                 page_texts[page_num] = []\n",
                "            #             page_texts[page_num].append(elem.text)\n",
                "                \n",
                "            #     num_pages = len(page_texts)\n",
                "                \n",
                "            #     for page_num, texts in page_texts.items():\n",
                "            #         text = '\\n'.join(texts)\n",
                "            #         output_path = self.dirs['text'] / f'page_{page_num}.txt'\n",
                "            #         with open(output_path, 'w', encoding='utf-8') as f:\n",
                "            #             f.write(text)\n",
                "                    \n",
                "            #         docs.append({\n",
                "            #             'content': text,\n",
                "            #             'metadata': {\n",
                "            #                 'page': page_num,\n",
                "            #                 'method': method,\n",
                "            #                 'file_path': str(output_path),\n",
                "            #                 'element_count': len(texts)\n",
                "            #             }\n",
                "            #         })\n",
                "                    \n",
                "            #         additional_info[f'page_{page_num}'] = {\n",
                "            #             'word_count': len(text.split()),\n",
                "            #             'char_count': len(text),\n",
                "            #             'elements': len(texts)\n",
                "            #         }\n",
                "            \n",
                "            success = True\n",
                "            error_msg = None\n",
                "            items = len(docs)\n",
                "                \n",
                "        except Exception as e:\n",
                "            self.logger.error(f\"Error in text extraction: {str(e)}\")\n",
                "            docs = []\n",
                "            num_pages = 0\n",
                "            items = 0\n",
                "            success = False\n",
                "            error_msg = str(e)\n",
                "            additional_info = {'error_details': str(e)}\n",
                "        \n",
                "        stats = ExtractionStats(\n",
                "            method=method,\n",
                "            start_time=start_time,\n",
                "            end_time=datetime.now(),\n",
                "            execution_time=(datetime.now() - start_time).total_seconds(),\n",
                "            memory_usage_mb=self._get_memory_usage() - start_mem,\n",
                "            num_pages=num_pages,\n",
                "            items_extracted=items,\n",
                "            success=success,\n",
                "            error_message=error_msg,\n",
                "            additional_info=additional_info\n",
                "        )\n",
                "        \n",
                "        self.current_stats['text'] = stats\n",
                "        return docs, stats\n",
                "\n",
                "    def extract_tables(self, pdf_path: str) -> Tuple[List[Dict], ExtractionStats]:\n",
                "        \"\"\"Extract tables using configured method\"\"\"\n",
                "        method = self.methods['tables']\n",
                "        start_time = datetime.now()\n",
                "        start_mem = self._get_memory_usage()\n",
                "        \n",
                "        try:\n",
                "            tables = []\n",
                "            additional_info = {}\n",
                "            \n",
                "            if method == 'camelot':\n",
                "                # Extract tables with both lattice and stream parsers\n",
                "                for parser in ['lattice', 'stream']:\n",
                "                    extracted_tables = camelot.read_pdf(\n",
                "                        pdf_path, \n",
                "                        pages='all',\n",
                "                        flavor=parser\n",
                "                    )\n",
                "                    \n",
                "                    for idx, table in enumerate(extracted_tables):\n",
                "                        page_num = table.parsing_report['page']\n",
                "                        table_num = len(tables) + 1\n",
                "\n",
                "                        \n",
                "                        # Save as CSV\n",
                "                        csv_path = self.dirs['tables'] / f'page_{page_num}_table_{idx}.csv'\n",
                "                        table.df.to_csv(csv_path, index=False)\n",
                "                        \n",
                "                        # Save as JSON for better metadata preservation\n",
                "                        json_path = self.dirs['tables'] / f'table_{table_num}_{parser}.json'\n",
                "                        table_data = {\n",
                "                            'data': table.data,\n",
                "                            'parsing_report': table.parsing_report\n",
                "                        }\n",
                "                        with open(json_path, 'w') as f:\n",
                "                            json.dump(table_data, f, indent=2)\n",
                "                        \n",
                "                        tables.append({\n",
                "                            'content': table.df.to_dict(),\n",
                "                            'metadata': {\n",
                "                                'table_number': table_num,\n",
                "                                'parser': parser,\n",
                "                                'page': table.parsing_report['page'],\n",
                "                                'accuracy': table.parsing_report['accuracy'],\n",
                "                                'whitespace': table.parsing_report['whitespace'],\n",
                "                                'csv_path': str(csv_path),\n",
                "                                'json_path': str(json_path)\n",
                "                            }\n",
                "                        })\n",
                "                        \n",
                "                        additional_info[f'table_{table_num}'] = {\n",
                "                            'rows': len(table.df),\n",
                "                            'columns': len(table.df.columns),\n",
                "                            'parser': parser,\n",
                "                            'accuracy': table.parsing_report['accuracy']\n",
                "                        }\n",
                "            elif method == 'pdfplumber':\n",
                "                with pdfplumber.open(pdf_path) as pdf:\n",
                "                    for page_num, page in enumerate(pdf.pages, 1):\n",
                "                        extracted_tables = page.extract_tables()\n",
                "                        \n",
                "                        for table_num, table in enumerate(extracted_tables, 1):\n",
                "                            if table and len(table) > 0:\n",
                "                                # Convert to DataFrame\n",
                "                                df = pd.DataFrame(table[1:], columns=table[0])\n",
                "                                \n",
                "                                # Save as CSV\n",
                "                                csv_path = self.dirs['tables'] / f'page_{page_num}_table_{table_num}.csv'\n",
                "                                df.to_csv(csv_path, index=False)\n",
                "                                \n",
                "                                # Save as JSON\n",
                "                                json_path = self.dirs['tables'] / f'page_{page_num}_table_{table_num}.json'\n",
                "                                table_data = {\n",
                "                                    'data': table,\n",
                "                                    'columns': table[0],\n",
                "                                    'rows': table[1:],\n",
                "                                    'dimensions': {\n",
                "                                        'rows': len(table),\n",
                "                                        'columns': len(table[0]) if table else 0\n",
                "                                    }\n",
                "                                }\n",
                "                                \n",
                "                                with open(json_path, 'w') as f:\n",
                "                                    json.dump(table_data, f, indent=2)\n",
                "                                \n",
                "                                metadata = {\n",
                "                                    'table_number': table_num,\n",
                "                                    'page': page_num,\n",
                "                                    'dimensions': table_data['dimensions'],\n",
                "                                    'csv_path': str(csv_path),\n",
                "                                    'json_path': str(json_path)\n",
                "                                }\n",
                "                                \n",
                "                                # Save structured metadata\n",
                "                                self.save_structured_metadata(\n",
                "                                    'table', \n",
                "                                    page_num, \n",
                "                                    table_num, \n",
                "                                    metadata\n",
                "                                )\n",
                "                                \n",
                "                                tables.append({\n",
                "                                    'content': df.to_dict(),\n",
                "                                    'metadata': metadata\n",
                "                                })\n",
                "                                \n",
                "                                additional_info[f'table_{page_num}_{table_num}'] = {\n",
                "                                    'rows': len(df),\n",
                "                                    'columns': len(df.columns)\n",
                "                                }\n",
                "            # elif method == 'unstructured':\n",
                "            #     elements = partition_pdf(pdf_path, strategy=\"hi_res\")\n",
                "            #     table_elements = [e for e in elements if e.category == 'table']\n",
                "                \n",
                "            #     for idx, table in enumerate(table_elements):\n",
                "            #         output_path = self.dirs['tables'] / f'table_{idx + 1}.txt'\n",
                "            #         with open(output_path, 'w') as f:\n",
                "            #             f.write(table.text)\n",
                "                    \n",
                "            #         tables.append({\n",
                "            #             'content': table.text,\n",
                "            #             'metadata': {\n",
                "            #                 'table_number': idx + 1,\n",
                "            #                 'page': table.metadata.get('page_number'),\n",
                "            #                 'file_path': str(output_path)\n",
                "            #             }\n",
                "            #         })\n",
                "                    \n",
                "            #         additional_info[f'table_{idx + 1}'] = {\n",
                "            #             'page': table.metadata.get('page_number'),\n",
                "            #             'text_length': len(table.text)\n",
                "            #         }\n",
                "            \n",
                "            success = True\n",
                "            error_msg = None\n",
                "            num_pages = len(set(t['metadata']['page'] for t in tables))\n",
                "            items = len(tables)\n",
                "            \n",
                "        except Exception as e:\n",
                "            self.logger.error(f\"Error in table extraction: {str(e)}\")\n",
                "            tables = []\n",
                "            num_pages = 0\n",
                "            items = 0\n",
                "            success = False\n",
                "            error_msg = str(e)\n",
                "            additional_info = {'error_details': str(e)}\n",
                "        \n",
                "        stats = ExtractionStats(\n",
                "            method=method,\n",
                "            start_time=start_time,\n",
                "            end_time=datetime.now(),\n",
                "            execution_time=(datetime.now() - start_time).total_seconds(),\n",
                "            memory_usage_mb=self._get_memory_usage() - start_mem,\n",
                "            num_pages=num_pages,\n",
                "            items_extracted=items,\n",
                "            success=success,\n",
                "            error_message=error_msg,\n",
                "            additional_info=additional_info\n",
                "        )\n",
                "        \n",
                "        self.current_stats['tables'] = stats\n",
                "        return tables, stats\n",
                "\n",
                "    def extract_images(self, pdf_path: str) -> Tuple[List[Dict], ExtractionStats]:\n",
                "        \"\"\"Extract images using configured method with OCR\"\"\"\n",
                "        method = self.methods['images']\n",
                "        start_time = datetime.now()\n",
                "        start_mem = self._get_memory_usage()\n",
                "        \n",
                "        try:\n",
                "            images = []\n",
                "            additional_info = {}\n",
                "            \n",
                "            if method == 'pymupdf':\n",
                "                doc = pymupdf.open(pdf_path)\n",
                "                \n",
                "                for page_num in range(doc.page_count):\n",
                "                    page = doc[page_num]\n",
                "                    image_list = page.get_images()\n",
                "                    \n",
                "                    for img_idx, img in enumerate(image_list):\n",
                "                        xref = img[0]\n",
                "                        base_image = doc.extract_image(xref)\n",
                "                        \n",
                "                        if base_image:\n",
                "                            image_bytes = base_image[\"image\"]\n",
                "                            image = Image.open(io.BytesIO(image_bytes))\n",
                "                            \n",
                "                            # Save image\n",
                "                            output_path = self.dirs['images'] / f'page_{page_num + 1}_img_{img_idx + 1}.png'\n",
                "                            image.save(output_path)\n",
                "                            \n",
                "                            # Perform OCR\n",
                "                            try:\n",
                "                                ocr_result = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
                "                                ocr_text = pytesseract.image_to_string(image)\n",
                "                            except Exception as e:\n",
                "                                ocr_result = {\"error\": str(e)}\n",
                "                                ocr_text = \"\"\n",
                "                            \n",
                "                            metadata = {\n",
                "                                'page': page_num + 1,\n",
                "                                'image_number': img_idx + 1,\n",
                "                                'width': image.width,\n",
                "                                'height': image.height,\n",
                "                                'format': image.format,\n",
                "                                'mode': image.mode,\n",
                "                                'file_path': str(output_path),\n",
                "                                'colorspace': base_image.get('colorspace'),\n",
                "                                'extension': base_image.get('ext'),\n",
                "                                'ocr': {\n",
                "                                    'text': ocr_text,\n",
                "                                    'confidence': ocr_result.get('conf', []),\n",
                "                                    'words': ocr_result.get('text', []),\n",
                "                                    'word_coordinates': list(zip(\n",
                "                                        ocr_result.get('left', []),\n",
                "                                        ocr_result.get('top', []),\n",
                "                                        ocr_result.get('width', []),\n",
                "                                        ocr_result.get('height', [])\n",
                "                                    ))\n",
                "                                }\n",
                "                            }\n",
                "                            \n",
                "                            # Save structured metadata\n",
                "                            self.save_structured_metadata(\n",
                "                                'image', \n",
                "                                page_num + 1, \n",
                "                                img_idx + 1, \n",
                "                                metadata\n",
                "                            )\n",
                "                            \n",
                "                            images.append({\n",
                "                                'image': image,\n",
                "                                'metadata': metadata\n",
                "                            })\n",
                "                            \n",
                "                            additional_info[f'image_{page_num + 1}_{img_idx + 1}'] = {\n",
                "                                'size': os.path.getsize(output_path),\n",
                "                                'dimensions': f\"{image.width}x{image.height}\",\n",
                "                                'format': image.format,\n",
                "                                'ocr_confidence': sum(ocr_result.get('conf', [0])) / len(ocr_result.get('conf', [1]))\n",
                "                            }\n",
                "                \n",
                "            success = True\n",
                "            error_msg = None\n",
                "            num_pages = len(set(img['metadata']['page'] for img in images))\n",
                "            items = len(images)\n",
                "            \n",
                "        except Exception as e:\n",
                "            self.logger.error(f\"Error in image extraction: {str(e)}\")\n",
                "            images = []\n",
                "            num_pages = 0\n",
                "            items = 0\n",
                "            success = False\n",
                "            error_msg = str(e)\n",
                "            additional_info = {'error_details': str(e)}\n",
                "        \n",
                "        stats = ExtractionStats(\n",
                "            method=method,\n",
                "            start_time=start_time,\n",
                "            end_time=datetime.now(),\n",
                "            execution_time=(datetime.now() - start_time).total_seconds(),\n",
                "            memory_usage_mb=self._get_memory_usage() - start_mem,\n",
                "            num_pages=num_pages,\n",
                "            items_extracted=items,\n",
                "            success=success,\n",
                "            error_message=error_msg,\n",
                "            additional_info=additional_info\n",
                "        )\n",
                "        \n",
                "        self.current_stats['images'] = stats\n",
                "        return images, stats\n",
                "\n",
                "    def save_experiment_results(self, pdf_path: str, results: Dict):\n",
                "        \"\"\"Save experiment results and metadata\"\"\"\n",
                "        experiment_dir = self.dirs['experiments'] / self.experiment_name\n",
                "        experiment_dir.mkdir(exist_ok=True)\n",
                "        \n",
                "        # Save statistics\n",
                "        stats_file = experiment_dir / 'extraction_stats.json'\n",
                "        stats_data = {\n",
                "            'pdf_file': pdf_path,\n",
                "            'timestamp': datetime.now().isoformat(),\n",
                "            'methods_used': self.methods,\n",
                "            'statistics': {\n",
                "                k: asdict(v) for k, v in self.current_stats.items()\n",
                "            }\n",
                "        }\n",
                "        \n",
                "        with open(stats_file, 'w') as f:\n",
                "            json.dump(stats_data, f, indent=2, default=str)\n",
                "        \n",
                "        # Save results summary\n",
                "        summary_file = experiment_dir / 'results_summary.json'\n",
                "        summary_data = {\n",
                "            'text_extracted': len(results.get('text', {}).get('data', [])),\n",
                "            'tables_extracted': len(results.get('tables', {}).get('data', [])),\n",
                "            'images_extracted': len(results.get('images', {}).get('data', [])),\n",
                "            'output_directory': str(self.output_dir)\n",
                "        }\n",
                "        \n",
                "        with open(summary_file, 'w') as f:\n",
                "            json.dump(summary_data, f, indent=2)\n",
                "    \n",
                "    def generate_performance_report(self) -> Dict:\n",
                "        \"\"\"\n",
                "        Generate comprehensive performance report for the extraction process\n",
                "        \n",
                "        Returns:\n",
                "            Dictionary containing detailed performance metrics\n",
                "        \"\"\"\n",
                "        report = {\n",
                "            'summary': {\n",
                "                'total_execution_time': 0,\n",
                "                'total_memory_used': 0,\n",
                "                'total_items_extracted': 0,\n",
                "                'success_rate': 0\n",
                "            },\n",
                "            'methods_used': self.methods,\n",
                "            'detailed_metrics': {},\n",
                "            'extraction_counts': {},\n",
                "            'errors': []\n",
                "        }\n",
                "        \n",
                "        successful_extractions = 0\n",
                "        total_extractions = 0\n",
                "        \n",
                "        for content_type, stats in self.current_stats.items():\n",
                "            # Accumulate summary metrics\n",
                "            report['summary']['total_execution_time'] += stats.execution_time\n",
                "            report['summary']['total_memory_used'] += stats.memory_usage_mb\n",
                "            report['summary']['total_items_extracted'] += stats.items_extracted\n",
                "            \n",
                "            # Track success rate\n",
                "            total_extractions += 1\n",
                "            if stats.success:\n",
                "                successful_extractions += 1\n",
                "            \n",
                "            # Detailed metrics per content type\n",
                "            report['detailed_metrics'][content_type] = {\n",
                "                'method_used': stats.method,\n",
                "                'execution_time': f\"{stats.execution_time:.2f} seconds\",\n",
                "                'memory_usage': f\"{stats.memory_usage_mb:.2f} MB\",\n",
                "                'pages_processed': stats.num_pages,\n",
                "                'items_extracted': stats.items_extracted,\n",
                "                'success': stats.success\n",
                "            }\n",
                "            \n",
                "            # Extraction counts\n",
                "            report['extraction_counts'][content_type] = {\n",
                "                'total_items': stats.items_extracted,\n",
                "                'items_per_page': stats.items_extracted / stats.num_pages if stats.num_pages > 0 else 0\n",
                "            }\n",
                "            \n",
                "            # Collect any errors\n",
                "            if stats.error_message:\n",
                "                report['errors'].append({\n",
                "                    'content_type': content_type,\n",
                "                    'error': stats.error_message\n",
                "                })\n",
                "        \n",
                "        # Calculate final summary metrics\n",
                "        report['summary']['success_rate'] = (\n",
                "            successful_extractions / total_extractions * 100 \n",
                "            if total_extractions > 0 else 0\n",
                "        )\n",
                "        \n",
                "        return report\n",
                "\n",
                "    def print_performance_report(self):\n",
                "        \"\"\"Print formatted performance report to console\"\"\"\n",
                "        report = self.generate_performance_report()\n",
                "        \n",
                "        print(\"\\n\" + \"=\"*50)\n",
                "        print(\"PDF EXTRACTION PERFORMANCE REPORT\")\n",
                "        print(\"=\"*50)\n",
                "        \n",
                "        # Overall Summary\n",
                "        print(\"\\n🔍 OVERALL SUMMARY:\")\n",
                "        print(f\"Total Execution Time: {report['summary']['total_execution_time']:.2f} seconds\")\n",
                "        print(f\"Total Memory Used: {report['summary']['total_memory_used']:.2f} MB\")\n",
                "        print(f\"Total Items Extracted: {report['summary']['total_items_extracted']}\")\n",
                "        print(f\"Overall Success Rate: {report['summary']['success_rate']:.1f}%\")\n",
                "        \n",
                "        # Methods Used\n",
                "        print(\"\\n🛠️ METHODS USED:\")\n",
                "        for content_type, method in report['methods_used'].items():\n",
                "            print(f\"{content_type.title()}: {method}\")\n",
                "        \n",
                "        # Detailed Metrics\n",
                "        print(\"\\n📊 DETAILED METRICS:\")\n",
                "        for content_type, metrics in report['detailed_metrics'].items():\n",
                "            print(f\"\\n{content_type.upper()}:\")\n",
                "            print(f\"  Method: {metrics['method_used']}\")\n",
                "            print(f\"  Execution Time: {metrics['execution_time']}\")\n",
                "            print(f\"  Memory Usage: {metrics['memory_usage']}\")\n",
                "            print(f\"  Pages Processed: {metrics['pages_processed']}\")\n",
                "            print(f\"  Items Extracted: {metrics['items_extracted']}\")\n",
                "            print(f\"  Success: {'✅' if metrics['success'] else '❌'}\")\n",
                "        \n",
                "        # Extraction Counts\n",
                "        print(\"\\n📈 EXTRACTION STATISTICS:\")\n",
                "        for content_type, counts in report['extraction_counts'].items():\n",
                "            print(f\"\\n{content_type.title()}:\")\n",
                "            print(f\"  Total Items: {counts['total_items']}\")\n",
                "            print(f\"  Items per Page: {counts['items_per_page']:.2f}\")\n",
                "        \n",
                "        # Errors\n",
                "        if report['errors']:\n",
                "            print(\"\\n⚠️ ERRORS ENCOUNTERED:\")\n",
                "            for error in report['errors']:\n",
                "                print(f\"\\n{error['content_type'].upper()}:\")\n",
                "                print(f\"  {error['error']}\")\n",
                "        \n",
                "        print(\"\\n\" + \"=\"*50)\n",
                "\n",
                "    def process_pdf(self, pdf_path: str, extract_types: Optional[List[str]] = None, show_performance: bool = True) -> Dict:\n",
                "        \"\"\"\n",
                "        Process PDF with configured methods\n",
                "        \n",
                "        Args:\n",
                "            pdf_path: Path to PDF file\n",
                "            extract_types: List of types to extract ('text', 'tables', 'images'). \n",
                "                         If None, extracts all types.\n",
                "        \n",
                "        Returns:\n",
                "            Dictionary with extraction results and statistics\n",
                "        \"\"\"\n",
                "        self.logger.info(f\"Processing PDF: {pdf_path}\")\n",
                "        extract_types = extract_types or ['text', 'tables', 'images']\n",
                "        results = {}\n",
                "        \n",
                "        # Validate PDF exists\n",
                "        if not os.path.exists(pdf_path):\n",
                "            raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
                "        \n",
                "        # Extract each type\n",
                "        extraction_methods = {\n",
                "            'text': self.extract_text,\n",
                "            'tables': self.extract_tables,\n",
                "            'images': self.extract_images\n",
                "        }\n",
                "        \n",
                "        for extract_type in extract_types:\n",
                "            if extract_type in extraction_methods:\n",
                "                self.logger.info(\n",
                "                    f\"Extracting {extract_type} using {self.methods[extract_type]}\"\n",
                "                )\n",
                "                data, stats = extraction_methods[extract_type](pdf_path)\n",
                "                results[extract_type] = {\n",
                "                    'data': data,\n",
                "                    'stats': asdict(stats)\n",
                "                }\n",
                "        \n",
                "        # Save experiment results if enabled\n",
                "        if self.save_metadata:\n",
                "            self.save_experiment_results(pdf_path, results)\n",
                "\n",
                "        if show_performance:\n",
                "            self.print_performance_report()\n",
                "        \n",
                "        return results\n",
                "\n",
                "    def get_extraction_summary(self) -> Dict:\n",
                "        \"\"\"Get summary of current extraction process\"\"\"\n",
                "        summary = {\n",
                "            'methods_used': self.methods,\n",
                "            'output_directory': str(self.output_dir),\n",
                "            'statistics': {\n",
                "                k: asdict(v) for k, v in self.current_stats.items()\n",
                "            }\n",
                "        }\n",
                "        return summary\n",
                "    \n",
                "    # save results to a json file in experiment directory\n",
                "    def save_results(self, results: Dict):\n",
                "        \"\"\"Save extraction results to a JSON file\"\"\"\n",
                "        experiment_dir = self.dirs['experiments'] / self.experiment_name\n",
                "        experiment_dir.mkdir(exist_ok=True)\n",
                "        \n",
                "        results_file = experiment_dir / 'extraction_results.json'\n",
                "        with open(results_file, 'w') as f:\n",
                "            json.dump(results, f, indent=4)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the path to the PDF file to be processed\n",
                "pdf_path = \"2024-2029_NationalOCSProgram_PFP_Sept_2023_Compliant_distilled.pdf\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the PDFExtractor with default settings\n",
                "EXPERIMENT_NAME = \"Default_Experiment_pymupdf_camelot\"\n",
                "extractor = PDFExtractor(\n",
                "    output_dir= EXPERIMENT_NAME,\n",
                "    experiment_name= EXPERIMENT_NAME,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-12-13 01:43:07,884 - PDFExtractor - INFO - Processing PDF: 2024-2029_NationalOCSProgram_PFP_Sept_2023_Compliant_distilled.pdf\n",
                        "2024-12-13 01:43:07,885 - PDFExtractor - INFO - Extracting text using pymupdf\n",
                        "2024-12-13 01:43:08,640 - PDFExtractor - INFO - Extracting tables using camelot\n",
                        "2024-12-13 01:43:31,828 - PDFExtractor - INFO - Extracting images using pymupdf\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "PDF EXTRACTION PERFORMANCE REPORT\n",
                        "==================================================\n",
                        "\n",
                        "🔍 OVERALL SUMMARY:\n",
                        "Total Execution Time: 38.95 seconds\n",
                        "Total Memory Used: 1.21 MB\n",
                        "Total Items Extracted: 144\n",
                        "Overall Success Rate: 100.0%\n",
                        "\n",
                        "🛠️ METHODS USED:\n",
                        "Text: pymupdf\n",
                        "Tables: camelot\n",
                        "Images: pymupdf\n",
                        "\n",
                        "📊 DETAILED METRICS:\n",
                        "\n",
                        "TEXT:\n",
                        "  Method: pymupdf\n",
                        "  Execution Time: 0.75 seconds\n",
                        "  Memory Usage: 0.00 MB\n",
                        "  Pages Processed: 53\n",
                        "  Items Extracted: 53\n",
                        "  Success: ✅\n",
                        "\n",
                        "TABLES:\n",
                        "  Method: camelot\n",
                        "  Execution Time: 23.18 seconds\n",
                        "  Memory Usage: 1.21 MB\n",
                        "  Pages Processed: 49\n",
                        "  Items Extracted: 64\n",
                        "  Success: ✅\n",
                        "\n",
                        "IMAGES:\n",
                        "  Method: pymupdf\n",
                        "  Execution Time: 15.01 seconds\n",
                        "  Memory Usage: 0.00 MB\n",
                        "  Pages Processed: 22\n",
                        "  Items Extracted: 27\n",
                        "  Success: ✅\n",
                        "\n",
                        "📈 EXTRACTION STATISTICS:\n",
                        "\n",
                        "Text:\n",
                        "  Total Items: 53\n",
                        "  Items per Page: 1.00\n",
                        "\n",
                        "Tables:\n",
                        "  Total Items: 64\n",
                        "  Items per Page: 1.31\n",
                        "\n",
                        "Images:\n",
                        "  Total Items: 27\n",
                        "  Items per Page: 1.23\n",
                        "\n",
                        "==================================================\n"
                    ]
                }
            ],
            "source": [
                "# Process the PDF and display the performance report\n",
                "results = extractor.process_pdf(pdf_path)\n",
                "\n",
                "# Or get performance report later\n",
                "# extractor.print_performance_report()\n",
                "\n",
                "# Get raw performance data for custom analysis\n",
                "performance_data = extractor.generate_performance_report()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-12-13 01:45:28,254 - PDFExtractor - INFO - Processing PDF: 2024-2029_NationalOCSProgram_PFP_Sept_2023_Compliant_distilled.pdf\n",
                        "2024-12-13 01:45:28,255 - PDFExtractor - INFO - Extracting text using pypdf\n",
                        "2024-12-13 01:45:29,126 - PDFExtractor - INFO - Extracting tables using camelot\n",
                        "2024-12-13 01:45:52,414 - PDFExtractor - INFO - Extracting images using pymupdf\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "PDF EXTRACTION PERFORMANCE REPORT\n",
                        "==================================================\n",
                        "\n",
                        "🔍 OVERALL SUMMARY:\n",
                        "Total Execution Time: 37.66 seconds\n",
                        "Total Memory Used: 268.45 MB\n",
                        "Total Items Extracted: 144\n",
                        "Overall Success Rate: 100.0%\n",
                        "\n",
                        "🛠️ METHODS USED:\n",
                        "Text: pypdf\n",
                        "Tables: camelot\n",
                        "Images: pymupdf\n",
                        "\n",
                        "📊 DETAILED METRICS:\n",
                        "\n",
                        "TEXT:\n",
                        "  Method: pypdf\n",
                        "  Execution Time: 0.87 seconds\n",
                        "  Memory Usage: 0.00 MB\n",
                        "  Pages Processed: 53\n",
                        "  Items Extracted: 53\n",
                        "  Success: ✅\n",
                        "\n",
                        "TABLES:\n",
                        "  Method: camelot\n",
                        "  Execution Time: 23.29 seconds\n",
                        "  Memory Usage: 268.45 MB\n",
                        "  Pages Processed: 49\n",
                        "  Items Extracted: 64\n",
                        "  Success: ✅\n",
                        "\n",
                        "IMAGES:\n",
                        "  Method: pymupdf\n",
                        "  Execution Time: 13.50 seconds\n",
                        "  Memory Usage: 0.00 MB\n",
                        "  Pages Processed: 22\n",
                        "  Items Extracted: 27\n",
                        "  Success: ✅\n",
                        "\n",
                        "📈 EXTRACTION STATISTICS:\n",
                        "\n",
                        "Text:\n",
                        "  Total Items: 53\n",
                        "  Items per Page: 1.00\n",
                        "\n",
                        "Tables:\n",
                        "  Total Items: 64\n",
                        "  Items per Page: 1.31\n",
                        "\n",
                        "Images:\n",
                        "  Total Items: 27\n",
                        "  Items per Page: 1.23\n",
                        "\n",
                        "==================================================\n"
                    ]
                }
            ],
            "source": [
                "# Initialize the PDFExtractor with PyPDF for text extraction\n",
                "EXPERIMENT_NAME = \"Default_Experiment_pypdf_camelot_pymupdf\"\n",
                "extractor = PDFExtractor(\n",
                "    output_dir= EXPERIMENT_NAME,\n",
                "    experiment_name= EXPERIMENT_NAME,\n",
                "    extract_text_method=\"pypdf\",\n",
                "    save_metadata=True\n",
                ")\n",
                "\n",
                "\n",
                "# Process the PDF and display the performance report\n",
                "results = extractor.process_pdf(pdf_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-12-13 01:54:30,918 - PDFExtractor - INFO - Processing PDF: 2024-2029_NationalOCSProgram_PFP_Sept_2023_Compliant_distilled.pdf\n",
                        "2024-12-13 01:54:30,920 - PDFExtractor - INFO - Extracting text using pypdf\n",
                        "2024-12-13 01:54:33,509 - PDFExtractor - INFO - Extracting tables using pdfplumber\n",
                        "2024-12-13 01:54:42,199 - PDFExtractor - INFO - Extracting images using pymupdf\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "PDF EXTRACTION PERFORMANCE REPORT\n",
                        "==================================================\n",
                        "\n",
                        "🔍 OVERALL SUMMARY:\n",
                        "Total Execution Time: 25.09 seconds\n",
                        "Total Memory Used: 89.02 MB\n",
                        "Total Items Extracted: 102\n",
                        "Overall Success Rate: 100.0%\n",
                        "\n",
                        "🛠️ METHODS USED:\n",
                        "Text: pypdf\n",
                        "Tables: pdfplumber\n",
                        "Images: pymupdf\n",
                        "\n",
                        "📊 DETAILED METRICS:\n",
                        "\n",
                        "TEXT:\n",
                        "  Method: pypdf\n",
                        "  Execution Time: 2.59 seconds\n",
                        "  Memory Usage: -240.00 MB\n",
                        "  Pages Processed: 53\n",
                        "  Items Extracted: 53\n",
                        "  Success: ✅\n",
                        "\n",
                        "TABLES:\n",
                        "  Method: pdfplumber\n",
                        "  Execution Time: 8.69 seconds\n",
                        "  Memory Usage: 127.05 MB\n",
                        "  Pages Processed: 11\n",
                        "  Items Extracted: 22\n",
                        "  Success: ✅\n",
                        "\n",
                        "IMAGES:\n",
                        "  Method: pymupdf\n",
                        "  Execution Time: 13.82 seconds\n",
                        "  Memory Usage: 201.96 MB\n",
                        "  Pages Processed: 22\n",
                        "  Items Extracted: 27\n",
                        "  Success: ✅\n",
                        "\n",
                        "📈 EXTRACTION STATISTICS:\n",
                        "\n",
                        "Text:\n",
                        "  Total Items: 53\n",
                        "  Items per Page: 1.00\n",
                        "\n",
                        "Tables:\n",
                        "  Total Items: 22\n",
                        "  Items per Page: 2.00\n",
                        "\n",
                        "Images:\n",
                        "  Total Items: 27\n",
                        "  Items per Page: 1.23\n",
                        "\n",
                        "==================================================\n"
                    ]
                }
            ],
            "source": [
                "# Initialize the PDFExtractor with PyPDF for text extraction and pdfplumber for table extraction\n",
                "EXPERIMENT_NAME = \"Default_Experiment_pypdf_pdfblumber_pymupdf\"\n",
                "extractor = PDFExtractor(\n",
                "    output_dir= EXPERIMENT_NAME,\n",
                "    experiment_name= EXPERIMENT_NAME,\n",
                "    extract_text_method=\"pypdf\",\n",
                "    extract_tables_method=\"pdfplumber\",\n",
                "    save_metadata=True\n",
                ")\n",
                "\n",
                "\n",
                "# Process PDF and see performance report\n",
                "results = extractor.process_pdf(pdf_path)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pdf_parser_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}